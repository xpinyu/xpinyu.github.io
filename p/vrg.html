<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Linum 团队从零训练 Image-Video VAE 的 5 个月旅程——最终学到一个违反直觉的教训：Better Reconstruction ≠ Better Generation。">
<title>Better Reconstruction ≠ Better Generation</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500&family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
<style>

  :root {
    --bg: #FAF6EE;
    --surface: #FFFFFF;
    --text-1: #1A1714;
    --text-2: #5C5349;
    --text-3: #776E62;
    --border: #E5DDD0;
    --accent: #1B3F8B;
    --vermillion: #E8432A;
    --ochre: #E8B830;
    --blue: #5A7A90;
    --blue-soft: #EAF0F5;
    --amber: #B8864A;
    --amber-bg: #F8F0E0;
    --red: #C0503A;
    --red-bg: #F8ECE8;
    --green: #4A8060;
    --green-bg: #E8F2EC;
    --purple: #7B6892;
    --purple-bg: #F0ECF5;
    --mono: 'JetBrains Mono', 'SF Mono', monospace;
    --serif: 'EB Garamond', 'Songti SC', Georgia, serif;
    --sans: 'Inter', -apple-system, 'PingFang SC', 'Noto Sans SC', sans-serif;
    --content-w: 680px;
    --wide-w: 780px;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }
  html { font-size: 16px; }
  @media (prefers-reduced-motion: no-preference) { html { scroll-behavior: smooth; } }

  body {
    font-family: var(--sans);
    background: var(--bg);
    color: var(--text-1);
    line-height: 1.85;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
  }

  /* ── Reading Progress ── */
  #progress {
    position: fixed; top: 0; left: 0; height: 2px;
    background: var(--accent); z-index: 999;
    transition: width 80ms linear; pointer-events: none;
  }

  /* ── Layout ── */
  .container { max-width: var(--content-w); margin: 0 auto; padding: 0 24px; }
  .wide { max-width: var(--wide-w); }

  /* ── Header ── */
  header {
    padding: 100px 0 48px;
    border-bottom: 1px solid var(--border);
    margin-bottom: 64px;
    animation: enter 0.6s ease both;
  }
  @keyframes enter {
    from { opacity: 0; transform: translateY(8px); }
  }
  header .eyebrow {
    font-size: 0.7rem; font-weight: 600;
    letter-spacing: 0.12em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 20px;
  }
  header h1 {
    font-family: var(--serif);
    font-size: 2.2rem; font-weight: 500;
    line-height: 1.25; letter-spacing: -0.02em;
    margin-bottom: 24px; max-width: 560px;
  }
  header h1 .sym { color: var(--accent); }
  header .subtitle {
    font-size: 1rem; color: var(--text-2);
    line-height: 1.9; max-width: 580px;
  }
  header .meta {
    margin-top: 28px; display: flex; gap: 24px;
    font-size: 0.75rem; color: var(--text-3); flex-wrap: wrap;
  }
  header .meta a {
    color: var(--text-3); text-decoration: none;
    border-bottom: 1px solid var(--border);
    transition: all 0.15s;
  }
  header .meta a:hover { color: var(--text-1); border-color: var(--text-1); }

  /* ── Thesis Card ── */
  .thesis {
    background: #1A2540; color: #F5F0EB;
    padding: 36px 40px; border-radius: 16px;
    margin-bottom: 72px; position: relative;
  }
  .thesis .thesis-label {
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.14em; text-transform: uppercase;
    opacity: 0.45; margin-bottom: 14px;
  }
  .thesis p {
    font-size: 1.05rem; line-height: 1.85;
    font-weight: 400;
  }
  .thesis strong { color: #E8B830; font-weight: 600; }
  .thesis .evidence {
    margin-top: 20px; padding-top: 18px;
    border-top: 1px solid rgba(255,255,255,0.1);
    font-size: 0.82rem; opacity: 0.65; line-height: 1.7;
  }
  .thesis .evidence em { font-style: normal; opacity: 0.85; }

  /* ── Sections ── */
  section { margin-bottom: 72px; }
  .section-num {
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.12em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 8px;
  }
  section > h2 {
    font-family: var(--serif);
    font-size: 1.5rem; font-weight: 600;
    line-height: 1.3; letter-spacing: -0.01em;
    margin-bottom: 6px;
  }
  section > .section-hook {
    font-size: 0.85rem; color: var(--text-3);
    margin-bottom: 24px; line-height: 1.6;
  }
  h3 {
    font-size: 1.1rem; font-weight: 600;
    margin: 40px 0 12px; letter-spacing: -0.01em;
  }
  p { margin-bottom: 18px; }
  p:last-child { margin-bottom: 0; }

  a { color: var(--accent); text-decoration: none; }
  a:hover { text-decoration: underline; }

  strong { font-weight: 600; }
  em { font-style: italic; color: var(--text-2); }

  /* ── Separator ── */
  .sep {
    height: 1px; background: var(--border);
    margin: 72px 0; border: none;
  }

  /* ── Pipeline Diagram ── */
  .pipeline {
    display: flex; align-items: center; justify-content: center;
    gap: 0; margin: 28px 0; flex-wrap: wrap;
    font-size: 0.82rem;
  }
  .pipe-node {
    padding: 10px 18px; border: 1px solid var(--border);
    background: var(--surface); font-weight: 500;
    text-align: center; white-space: nowrap;
  }
  .pipe-node:first-child { border-radius: 8px 0 0 8px; }
  .pipe-node:last-child { border-radius: 0 8px 8px 0; }
  .pipe-node + .pipe-node { border-left: none; }
  .pipe-node.is-encoder { background: var(--blue-soft); border-color: #DDD5CB; }
  .pipe-node.is-latent { background: var(--amber-bg); border-color: #DCC9A8; font-weight: 700; }
  .pipe-node.is-decoder { background: var(--green-bg); border-color: #B8D4C0; }

  /* ── Callout / Note ── */
  .note {
    padding: 20px 24px; border-radius: 12px;
    margin: 24px 0; font-size: 0.88rem; line-height: 1.8;
    border-left: 3px solid;
  }
  .note-label {
    font-size: 0.65rem; font-weight: 700;
    letter-spacing: 0.08em; text-transform: uppercase;
    margin-bottom: 6px;
  }
  .note-insight  { background: var(--amber-bg); border-color: var(--amber); }
  .note-insight .note-label { color: var(--amber); }
  .note-problem  { background: var(--red-bg);   border-color: var(--red); }
  .note-problem .note-label { color: var(--red); }
  .note-ok       { background: var(--green-bg); border-color: var(--green); }
  .note-ok .note-label { color: var(--green); }
  .note-neutral  { background: #F2EDE4; border-color: var(--border); color: var(--text-2); }
  .note-neutral .note-label { color: var(--text-3); }

  /* ── Loss Grid ── */
  .loss-grid {
    display: grid; grid-template-columns: 1fr 1fr;
    gap: 12px; margin: 24px 0;
  }
  @media (max-width: 600px) { .loss-grid { grid-template-columns: 1fr; } }
  .loss-item {
    padding: 16px 20px; background: var(--surface);
    border: 1px solid var(--border); border-radius: 12px;
  }
  .loss-name {
    font-size: 0.85rem; font-weight: 700; margin-bottom: 4px;
    display: flex; align-items: center; gap: 8px;
  }
  .loss-name .tag {
    font-size: 0.6rem; font-weight: 600; padding: 2px 8px;
    border-radius: 100px; letter-spacing: 0.02em;
  }
  .tag-reg  { background: var(--blue-soft); color: var(--blue); }
  .tag-base { background: var(--amber-bg); color: var(--amber); }
  .tag-sem  { background: #F0ECF5; color: #7B6892; }
  .tag-sharp { background: #F5ECF0; color: #926878; }
  .loss-desc { font-size: 0.8rem; color: var(--text-2); line-height: 1.7; }

  /* ── Data Table ── */
  table {
    width: 100%; border-collapse: collapse;
    margin: 24px 0; font-size: 0.82rem;
  }
  thead th {
    text-align: left; padding: 10px 14px;
    font-size: 0.7rem; font-weight: 600;
    letter-spacing: 0.04em; text-transform: uppercase;
    color: var(--text-3); border-bottom: 2px solid var(--border);
  }
  tbody td {
    padding: 10px 14px; border-bottom: 1px solid var(--border);
    vertical-align: top;
  }
  tbody tr:last-child td { border-bottom: none; }
  tr.row-ok td { background: var(--green-bg); }
  .badge {
    display: inline-block; font-size: 0.65rem; font-weight: 600;
    padding: 2px 8px; border-radius: 100px;
  }
  .badge-fail { background: var(--red-bg); color: var(--red); }
  .badge-ok   { background: var(--green-bg); color: var(--green); }

  /* ── Debug Timeline ── */
  .timeline {
    margin: 28px 0; padding-left: 0; list-style: none;
    position: relative;
  }
  .timeline::before {
    content: ''; position: absolute;
    left: 11px; top: 8px; bottom: 8px;
    width: 1px; background: var(--border);
  }
  .timeline li {
    position: relative; padding: 10px 0 10px 36px;
    font-size: 0.88rem; line-height: 1.75;
  }
  .timeline li::before {
    content: ''; position: absolute;
    left: 5px; top: 18px;
    width: 13px; height: 13px; border-radius: 50%;
    border: 2px solid var(--border); background: var(--bg);
  }
  .timeline .t-label {
    font-size: 0.62rem; font-weight: 700;
    letter-spacing: 0.06em; text-transform: uppercase;
    margin-bottom: 2px;
  }
  .tl-problem::before  { border-color: var(--red); background: var(--red-bg); }
  .tl-problem .t-label { color: var(--red); }
  .tl-try::before      { border-color: var(--amber); background: var(--amber-bg); }
  .tl-try .t-label     { color: var(--amber); }
  .tl-fix::before      { border-color: var(--green); background: var(--green-bg); }
  .tl-fix .t-label     { color: var(--green); }

  /* ── Expand / Details ── */
  details {
    margin: 20px 0; border: 1px solid var(--border);
    border-radius: 12px; overflow: hidden;
  }
  details summary {
    padding: 14px 20px; cursor: pointer;
    font-size: 0.82rem; font-weight: 500;
    color: var(--text-2); background: #F2EDE4;
    user-select: none; list-style: none;
    transition: background 0.15s;
  }
  details summary:hover { background: #EAE5DC; }
  details summary::-webkit-details-marker { display: none; }
  details summary::before { content: '+ '; font-weight: 700; color: var(--text-3); }
  details[open] summary::before { content: '− '; }
  details .expand-body {
    padding: 18px 20px; font-size: 0.85rem;
    line-height: 1.8; color: var(--text-2);
  }

  /* ── Option Cards ── */
  .options {
    display: grid; grid-template-columns: 1fr 1fr;
    gap: 16px; margin: 28px 0;
  }
  @media (max-width: 600px) { .options { grid-template-columns: 1fr; } }
  .opt {
    padding: 24px; background: var(--surface);
    border: 1px solid var(--border); border-radius: 14px;
    transition: border-color 0.2s, box-shadow 0.2s;
  }
  .opt:hover { border-color: #D0C8BD; box-shadow: 0 2px 12px rgba(0,0,0,0.04); }
  .opt-tag {
    font-size: 0.6rem; font-weight: 700;
    letter-spacing: 0.1em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 8px;
  }
  .opt h4 {
    font-size: 0.95rem; font-weight: 700;
    margin-bottom: 10px; line-height: 1.4;
  }
  .opt p { font-size: 0.82rem; color: var(--text-2); line-height: 1.7; margin-bottom: 12px; }
  .opt .refs { font-size: 0.72rem; color: var(--text-3); }
  .opt .refs a { font-size: 0.72rem; color: var(--accent); }

  /* ── Causal Chain ── */
  .causal {
    margin: 24px 0; padding: 0; list-style: none;
    counter-reset: cause;
  }
  .causal li {
    counter-increment: cause; position: relative;
    padding: 8px 0 8px 44px; font-size: 0.9rem;
    line-height: 1.75;
  }
  .causal li::before {
    content: counter(cause); position: absolute;
    left: 0; top: 10px;
    width: 28px; height: 28px; border-radius: 50%;
    background: #1A2540; color: #F5F0EB;
    font-size: 0.7rem; font-weight: 700;
    display: flex; align-items: center; justify-content: center;
  }
  .causal li + li { border-top: 1px dashed var(--border); }

  /* ── Code ── */
  code {
    font-family: var(--mono); font-size: 0.82em;
    background: #EDE8E0; padding: 2px 7px; border-radius: 5px;
  }

  /* ── Takeaway Footer ── */
  .takeaway {
    background: #1A2540; color: #F5F0EB;
    padding: 36px 40px; border-radius: 16px;
    margin: 72px 0 48px;
  }
  .takeaway .thesis-label {
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.14em; text-transform: uppercase;
    opacity: 0.45; margin-bottom: 12px;
  }
  .takeaway p { font-size: 1.05rem; line-height: 1.85; }
  .takeaway strong { color: #8EC5A0; font-weight: 600; }

  /* ── Top Bar ── */
  .topbar {
    position: fixed; top: 2px; left: 0; right: 0;
    z-index: 100; padding: 10px 24px;
    display: flex; justify-content: space-between; align-items: center;
    font-size: 0.72rem;
    background: rgba(250,246,238,0.85);
    backdrop-filter: blur(12px); -webkit-backdrop-filter: blur(12px);
    border-bottom: 1px solid rgba(229,221,208,0.6);
  }
  .topbar a {
    color: var(--text-3); text-decoration: none;
    transition: color 0.15s;
  }
  .topbar a:hover { color: var(--text-1); }
  .topbar .home-link { font-weight: 500; letter-spacing: 0.02em; }

  /* ── Footer ── */
  footer {
    text-align: center; padding: 48px 0 64px;
    font-size: 0.72rem; color: var(--text-3);
  }
  footer a { color: var(--text-3); border-bottom: 1px solid var(--border); text-decoration: none; }
  footer a:hover { color: var(--text-1); }

  /* ── Phase Marker ── */
  .phase {
    display: inline-flex; align-items: center; gap: 8px;
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.08em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 8px;
  }
  .phase::before {
    content: ''; width: 6px; height: 6px;
    border-radius: 50%; background: var(--accent);
  }
  .phase .dur {
    font-weight: 500; color: var(--accent);
    padding: 1px 8px; border-radius: 100px;
    background: var(--blue-soft); font-size: 0.6rem;
  }

  /* ── Versus Block ── */
  .versus {
    display: grid; grid-template-columns: 1fr auto 1fr;
    gap: 0; margin: 24px 0; font-size: 0.85rem;
    border: 1px solid var(--border); border-radius: 14px;
    overflow: hidden;
  }
  .versus .v-side { padding: 20px 24px; }
  .versus .v-label {
    font-size: 0.62rem; font-weight: 700;
    letter-spacing: 0.08em; text-transform: uppercase;
    margin-bottom: 6px;
  }
  .versus .v-left  { background: var(--red-bg); }
  .versus .v-left .v-label  { color: var(--red); }
  .versus .v-right { background: var(--green-bg); }
  .versus .v-right .v-label { color: var(--green); }
  .versus .v-mid {
    display: flex; align-items: center; justify-content: center;
    padding: 0 4px; font-weight: 700; color: var(--text-3);
    background: var(--bg); font-size: 0.75rem;
  }

  /* ── Focus ── */
  a:focus-visible,
  details summary:focus-visible {
    outline: 2px solid var(--accent);
    outline-offset: 3px;
    border-radius: 2px;
  }

  @media (prefers-reduced-motion: reduce) {
    header { animation: none; }
  }

  /* ── Responsive ── */
  @media (max-width: 600px) {
    header h1 { font-size: 1.6rem; }
    .thesis, .takeaway { padding: 28px 24px; }
    .versus { grid-template-columns: 1fr; }
    .versus .v-mid {
      padding: 8px; border-top: 1px solid var(--border);
      border-bottom: 1px solid var(--border);
    }
  }

  /* ── TOC ── */
  nav.toc {
    position: fixed; top: 100px;
    left: max(20px, calc((100vw - var(--content-w)) / 2 - 240px));
    width: 200px; font-size: 0.7rem; line-height: 1.6;
    z-index: 50;
  }
  @media (max-width: 1100px) { nav.toc { display: none; } }
  nav.toc a {
    display: block; padding: 4px 0 4px 14px;
    border-left: 1px solid var(--border);
    color: var(--text-3); text-decoration: none;
    transition: all 0.15s;
  }
  nav.toc a:hover, nav.toc a.active {
    color: var(--text-1); border-color: var(--text-1);
  }
  nav.toc .indent { padding-left: 26px; font-size: 0.65rem; }
</style>
</head>
<body>

<div class="topbar">
  <a class="home-link" href="/">← pinyu.ai</a>
</div>

<div id="progress" style="width:0%"></div>

<nav class="toc" id="toc">
  <a href="#paradox">核心悖论</a>
  <a href="#why-vae">为什么需要 VAE</a>
  <a href="#crash-course">VAE 工作原理</a>
  <a href="#baseline">阶段一：基线</a>
  <a href="#cotrain">阶段二：联合训练</a>
  <a class="indent" href="#loss-norm">Loss 归一化</a>
  <a class="indent" href="#nan-hell">NaN 地狱</a>
  <a class="indent" href="#spots">色斑问题</a>
  <a href="#multi-res">阶段三：多分辨率</a>
  <a href="#wan">为什么切换 Wan 2.1</a>
  <a href="#insight">核心洞察</a>
  <a href="#future">未来方向</a>
</nav>

<div class="container">

  <!-- ═══════════════════════ HEADER ═══════════════════════ -->
  <header>
    <div class="eyebrow">Linum Field Notes</div>
    <h1>Better Reconstruction <span class="sym">≠</span> Better Generation</h1>
    <p class="subtitle">
      Linum 团队从零训练 Image-Video VAE 的 5 个月旅程。踩过 NaN 爆炸、神秘色斑、联合训练不稳定——最终学到一个违反直觉的教训。
    </p>
    <div class="meta">
      <span>Linum AI · 2024.07 — 11</span>
      <a href="https://github.com/Linum-AI/image-video-vae" target="_blank">Model Code</a>
      <a href="https://huggingface.co/Linum-AI/image-video-vae" target="_blank">Weights</a>
      <a href="https://www.linum.ai/field-notes/vae-reconstruction-vs-generation" target="_blank">原文</a>
    </div>
  </header>

  <!-- ═══════════════════════ THESIS ═══════════════════════ -->
  <div class="thesis" id="paradox">
    <div class="thesis-label">Core Thesis</div>
    <p>
      VAE 重建质量越高，下游 Diffusion 的生成质量<strong>不一定更好——甚至可能更差</strong>。<br>
      因为过度优化重建 = 让 latent space 去记住噪声，扭曲了语义结构，让 Diffusion 更难学到真正的视觉概念。
    </p>
    <div class="evidence">
      <em>实证</em>：Yao et al. (2025) 将 VAE 的 rFID 从 0.49 提升到 0.18（重建更好），但下游 Diffusion 的 gFID 从 20.3 暴跌到 45.8（生成更差）。
    </div>
  </div>

  <!-- ═══════════════════════ §1 WHY VAE ═══════════════════════ -->
  <section id="why-vae">
    <div class="section-num">01</div>
    <h2>为什么需要 VAE</h2>
    <p class="section-hook">先建直觉——VAE 解决什么问题？</p>

    <p>
      当前最好的图像/视频生成模型都依赖 Diffusion Transformer。Transformer 的注意力机制是 O(n²)——序列越长，计算量越离谱。
    </p>

    <div class="note note-problem">
      <div class="note-label">量级感</div>
      一段 720p、5 秒、24fps 的视频 = <strong>1.1 亿个 token</strong>。<br>
      在像素空间直接算注意力？完全不可能。
    </div>

    <p>
      VAE 的职责只有一个：<strong>把视频压缩到一个紧凑的 latent space</strong>，让 Diffusion Transformer 在小得多的空间里工作。
    </p>

    <div class="pipeline">
      <div class="pipe-node">原始视频 x</div>
      <div class="pipe-node is-encoder">Encoder</div>
      <div class="pipe-node is-latent">latent z</div>
      <div class="pipe-node is-decoder">Decoder</div>
      <div class="pipe-node">重建 x̂</div>
    </div>

    <div class="note note-insight">
      <div class="note-label">认知锚点</div>
      VAE 不是目的，是管道。它的价值不在于"重建得多完美"，而在于"压缩后的 latent space 对下游学习是否友好"。这个认知将贯穿全文。
    </div>
  </section>

  <!-- ═══════════════════════ §2 CRASH COURSE ═══════════════════════ -->
  <section id="crash-course">
    <div class="section-num">02</div>
    <h2>VAE 工作原理</h2>
    <p class="section-hook">用 2 分钟建立足够的技术模型</p>

    <p>
      普通 Autoencoder：输入 → Encoder 压缩成小表示 → Decoder 重建。瓶颈结构迫使模型学到"什么是真正重要的"。
    </p>
    <p>
      <strong>Variational</strong> Autoencoder 加了一层：Encoder 不输出一个固定的点，而是输出一个<strong>概率分布的参数</strong>（均值 μ 和标准差 σ），从中采样 z 再送进 Decoder。
    </p>

    <div class="pipeline">
      <div class="pipe-node">x</div>
      <div class="pipe-node is-encoder">Encoder → μ, σ</div>
      <div class="pipe-node is-latent">采样 z ~ N(μ, σ²)</div>
      <div class="pipe-node is-decoder">Decoder</div>
      <div class="pipe-node">x̂</div>
    </div>

    <h3>训练目标：四项 Loss 协同</h3>

    <div class="loss-grid">
      <div class="loss-item">
        <div class="loss-name">L<sub>KL</sub> <span class="tag tag-reg">正则化</span></div>
        <div class="loss-desc">让 latent 分布接近标准正态，保证 latent space 平滑。权重极低 ~1e-6，几乎不在乎采样能力，只要平滑。</div>
      </div>
      <div class="loss-item">
        <div class="loss-name">L<sub>recon</sub> <span class="tag tag-base">基本功</span></div>
        <div class="loss-desc">L1 风格重建损失。输出应该像输入。带一个可学习的置信度参数。</div>
      </div>
      <div class="loss-item">
        <div class="loss-name">L<sub>perceptual</sub> <span class="tag tag-sem">语义层</span></div>
        <div class="loss-desc">过预训练 VGG 提特征、比中间层。"看起来像"比"像素一样"重要。</div>
      </div>
      <div class="loss-item">
        <div class="loss-name">L<sub>adversarial</sub> <span class="tag tag-sharp">锐化</span></div>
        <div class="loss-desc">借鉴 GAN：训判别器区分真假，VAE 要骗过它。逼出高频细节，防模糊。</div>
      </div>
    </div>

    <details>
      <summary>为什么要同时训练图像和视频？</summary>
      <div class="expand-body">
        训练 text-to-video 模型时，需要先在图像上预训练——模型得先理解"名词"（人、地点、物体），再理解"动词"（动作、运动、镜头）。所以 VAE 必须同时处理图像和视频，总 loss = L<sub>image</sub> + L<sub>video</sub>。
      </div>
    </details>
  </section>

  <hr class="sep">

  <!-- ═══════════════════════ §3 BASELINE ═══════════════════════ -->
  <section id="baseline">
    <div class="phase">阶段一 <span class="dur">1 周</span></div>
    <h2>构建纯视频 VAE 基线</h2>
    <p class="section-hook">先解决最简单的子问题</p>

    <p>
      2024 年秋天，没有好用的开源 Video VAE。他们从纯视频开始，用传统 CNN 架构将 Conv2D 替换为 Conv3D。
    </p>
    <p>
      FLUX-1 用 8x 空间下采样，但视频的最优压缩率未知。保守起步：4x 空间 + 4x 时间。<strong>开箱即用</strong>，重建几乎完美——但压缩率太低，360p 1 秒视频就 OOM（80GB H100）。
    </p>

    <div class="note note-problem">
      <div class="note-label">瓶颈定位</div>
      超线性内存增长来自 Encoder/Decoder 中的 <code>AttentionBlock</code>。解法：在 attention 之前多降采样。
    </div>

    <h3>压缩率实验</h3>
    <table>
      <thead>
        <tr><th>空间</th><th>时间</th><th>等效压缩率</th><th>结果</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>4x</td><td>4x</td><td>12x</td>
          <td><span class="badge badge-fail">不可用</span> 压缩不够，高分辨率 OOM</td>
        </tr>
        <tr>
          <td>8x</td><td>8x</td><td>96x</td>
          <td><span class="badge badge-fail">不可用</span> 重建质量崩坏</td>
        </tr>
        <tr>
          <td>16x</td><td>4x</td><td>192x</td>
          <td><span class="badge badge-fail">不可用</span> 重建质量崩坏</td>
        </tr>
        <tr class="row-ok">
          <td>8x</td><td>4x</td><td>48x</td>
          <td><span class="badge badge-ok">可用</span> 偶有伪影（180p 高运动场景）</td>
        </tr>
      </tbody>
    </table>

    <details>
      <summary>等效压缩率怎么算？</summary>
      <div class="expand-body">
        等效压缩率 = H 下采样 × W 下采样 × T 下采样 × (3 RGB 通道 / 16 latent 通道)<br>
        例如 8x 空间、4x 时间：8 × 8 × 4 × (3/16) = 48x
      </div>
    </details>

    <div class="note note-neutral">
      <div class="note-label">前瞻</div>
      <strong>自适应 tokenization 是未来。</strong>当前 latent 大小机械地绑定输入分辨率，而非内容复杂度。一个平静湖面和一场拳击赛信息量完全不同，但 latent 大小一样——这并不合理。
    </div>
  </section>

  <!-- ═══════════════════════ §4 CO-TRAIN ═══════════════════════ -->
  <section id="cotrain">
    <div class="phase">阶段二 <span class="dur">3 个月</span></div>
    <h2>图像-视频联合训练</h2>
    <p class="section-hook">整个项目最艰难的阶段——三个环环相扣的子问题</p>

    <p>
      为了让 VAE 同时处理图像，他们将每张图像 pad 成 4 帧"静态视频"（temporal downsample 压回 1 帧 latent）。视频重建正常，但<strong>图像重建一塌糊涂</strong>——细节模糊、面部不可辨。单独训图像完全没问题，所以问题出在联合训练的 loss 设计。
    </p>

    <!-- ── Sub1: Loss Normalization ── -->
    <h3 id="loss-norm">子问题 1：Loss 归一化</h3>

    <ul class="timeline">
      <li class="tl-problem">
        <div class="t-label">问题</div>
        <strong>Loss 按维度求和再除以 batch size。</strong>视频 tensor 比图像大 ~10x → 视频对 loss 贡献 ~10x → 优化器对图像信号"失明"。
      </li>
      <li class="tl-try">
        <div class="t-label">尝试：改用 mean per sample</div>
        归一化了 loss 量级，但副作用：每像素梯度反比于 tensor 大小。小图像中一个坏像素的梯度是大视频的 ~10x → 过度强调图像完美重建。
      </li>
      <li class="tl-fix">
        <div class="t-label">解法：参考形状归一化</div>
        保留 sum-based loss，但相对一个<strong>固定参考形状</strong>做归一化。既保持 loss 量级一致，又不扭曲每像素梯度，还能手动调节图像/视频权重。
      </li>
    </ul>

    <!-- ── Sub2: NaN Hell ── -->
    <h3 id="nan-hell">子问题 2：NaN 地狱</h3>
    <p>即使解决了 loss 归一化，加权后仍然频繁 NaN。</p>

    <ul class="timeline">
      <li class="tl-problem">
        <div class="t-label">症状</div>
        激活值和梯度的 L2 Norm 明显爆炸。
      </li>
      <li class="tl-try">
        <div class="t-label">尝试 1：到处加 GroupNorm</div>
        早期稳定了，深入训练后仍然爆炸。
      </li>
      <li class="tl-try">
        <div class="t-label">尝试 2：FiLM 条件层</div>
        让网络区分图像/视频模态。但 scale 参数一从 0 变非零，就触发梯度爆炸 → 放弃。
      </li>
      <li class="tl-fix">
        <div class="t-label">解法：自适应梯度裁剪 (AGC)</div>
        跟踪每个参数的梯度/权重范数比率的 EMA，超阈值则裁剪。<strong>训练终于稳定了</strong>——但带来了新问题 ↓
      </li>
    </ul>

    <!-- ── Sub3: Spots ── -->
    <h3 id="spots">子问题 3：色斑问题</h3>
    <p>AGC 稳定了训练，但重建图像上出现了<strong>彩色斑点</strong>（绿色、黑色色块随机出现）。</p>

    <div class="note note-problem">
      <div class="note-label">根因</div>
      <strong>GroupNorm 是罪魁祸首。</strong>组内归一化时，如果某个通道的激活值特别大，GroupNorm 会让它"独占话语权"，压制同组其他通道信号——表现在像素层面就是局部色斑。
    </div>

    <ul class="timeline">
      <li class="tl-try">
        <div class="t-label">方案 1：Self-Modulating Convolution (SMC)</div>
        不归一化激活值，改为归一化卷积权重。每个输入通道有独立缩放参数 + L2 归一化。<strong>180p 色斑消失 ✓</strong>
      </li>
      <li class="tl-problem">
        <div class="t-label">但是</div>
        升到 360p / 720p 后色斑又来了。通过 hook 逐层追踪 L2 Norm，定位到 <strong>Encoder Mid Block 的 <code>AttentionBlock</code> 中的 GroupNorm</strong>。
      </li>
      <li class="tl-fix">
        <div class="t-label">最终解法</div>
        将 Mid Block 的 GroupNorm 替换为更轻量的 <strong>Pixel Norm</strong>。色斑消除 ✓
      </li>
    </ul>

    <details>
      <summary>Meta MovieGen 的替代方案</summary>
      <div class="expand-body">
        Meta 在 MovieGen 论文中描述了同样的色斑问题，但解法不同：在 VAE loss 中添加一项惩罚激活值异常值的损失。由于 Meta 没有发布模型，无法验证效果。但这说明色斑问题有多种解法。
      </div>
    </details>
  </section>

  <!-- ═══════════════════════ §5 MULTI-RES ═══════════════════════ -->
  <section id="multi-res">
    <div class="phase">阶段三 <span class="dur">2 周</span></div>
    <h2>多分辨率训练</h2>

    <div class="note note-problem">
      <div class="note-label">灾难性遗忘</div>
      顺序训练 180p → 360p → 720p 后，最终 checkpoint 完全忘记了低分辨率的重建能力。而 Diffusion 模型需要跨分辨率训练，VAE 必须全分辨率可用。
    </div>

    <div class="note note-ok">
      <div class="note-label">解法</div>
      改课程策略：引入高分辨率时<strong>保留低分辨率训练</strong>。通过超参搜索确定各分辨率 loss 权重：
      <br><strong>180p</strong> → ~1.1（主力） · <strong>360p</strong> → 0.1 · <strong>720p</strong> → 0.01
    </div>
  </section>

  <!-- ═══════════════════════ §6 WAN ═══════════════════════ -->
  <section id="wan">
    <div class="section-num">06</div>
    <h2>为什么最终切换到 Wan 2.1 VAE</h2>

    <p>
      训练 Diffusion 时，数据集只需用 VAE 嵌入一次（离线）。2025 年 2 月 Wan 2.1 VAE 发布时，Linum 只嵌入了一小部分数据集，于是做了对比：
    </p>

    <table>
      <thead><tr><th></th><th>Linum VAE</th><th>Wan 2.1 VAE</th></tr></thead>
      <tbody>
        <tr><td>生成质量</td><td>✓</td><td>✓ 持平</td></tr>
        <tr><td>模型大小</td><td>较大</td><td><strong>更小</strong></td></tr>
        <tr><td>速度</td><td>全时空注意力</td><td><strong>更快</strong>（无全时空注意力）</td></tr>
        <tr><td>嵌入成本</td><td>高</td><td><strong>低</strong></td></tr>
      </tbody>
    </table>

    <p>务实选择：质量持平，Wan 更便宜 → 切换，省钱嵌入大数据集。</p>

    <div class="note note-neutral">
      <div class="note-label">元启示</div>
      VAE 是基础设施，不是护城河。没有差异化优势时，用社区最优解是理性选择。
    </div>
  </section>

  <hr class="sep">

  <!-- ═══════════════════════ §7 CORE INSIGHT ═══════════════════════ -->
  <section id="insight">
    <div class="section-num">核心</div>
    <h2>Better Reconstruction ≠ Better Generation</h2>
    <p class="section-hook">全文最重要的部分——回到开头的反直觉命题</p>

    <p>
      Linum 在构建 VAE 时执着于"完美重建"，花了数周优化那 ~10% 的困难样本。回头看，他们应该<strong>直接把这些样本过滤掉</strong>。
    </p>

    <h3>那 10% 的困难样本是什么？</h3>
    <p>
      几乎都是低质量数据：严重像素化的人脸、JPEG 压缩伪影遍布的图像、完全没有细节的树枝和纹理——都是激进 JPEG 压缩的产物。
    </p>

    <h3>关键因果链</h3>
    <ol class="causal">
      <li><strong>压缩伪影比真实细节更难重建</strong>——因为它们本质上是噪声</li>
      <li>逼 VAE 完美重建噪声 → latent space 被扭曲去"记住"噪声模式</li>
      <li>Diffusion 通过这个 latent space "看世界" → 学到的是噪声模式，不是视觉概念</li>
      <li><strong>生成质量反而更差</strong></li>
    </ol>

    <p>
      这也解释了为什么跨分辨率联合训练那么不稳定：模型在 180p 时把噪声理解烙进了表示空间，引入高分辨率数据时不得不彻底重塑 latent space。
    </p>

    <div class="versus">
      <div class="v-side v-left">
        <div class="v-label">直觉</div>
        更清晰的镜头 → Diffusion 更容易学到模式 → 生成更好
      </div>
      <div class="v-mid">VS</div>
      <div class="v-side v-right">
        <div class="v-label">现实</div>
        rFID 0.49→0.18（重建更好），gFID 20.3→45.8（生成更差）。你在优化镜头清晰度，但那个镜头同时放大了噪声。
      </div>
    </div>
  </section>

  <!-- ═══════════════════════ §8 FUTURE ═══════════════════════ -->
  <section id="future">
    <div class="section-num">展望</div>
    <h2>未来方向</h2>
    <p class="section-hook">如何创造一个"对下游学习友好"的 latent space？</p>

    <div class="options">
      <div class="opt">
        <div class="opt-tag">路线 A · 正则化 VAE</div>
        <h4>让 latent space 对齐语义表征</h4>
        <p>
          保留 VAE，但增加对齐损失——让 latent 表征与预训练视觉编码器（如 DINO）对齐。"压缩"的同时保留语义结构。
        </p>
        <p>
          可以端到端训练（不实际），也可以用对齐损失单独重训 VAE，或直接让更大 VAE 学习自监督表征。
        </p>
        <div class="refs">
          <a href="https://arxiv.org/abs/2410.06940">REPA</a> ·
          <a href="https://arxiv.org/abs/2501.01423">VA-VAE</a> ·
          <a href="https://arxiv.org/abs/2512.13687">VTP</a> ·
          <a href="https://arxiv.org/abs/2504.10483">Leng et al.</a>
        </div>
      </div>
      <div class="opt">
        <div class="opt-tag">路线 B · 去掉 VAE</div>
        <h4>让 Diffusion 自己学压缩</h4>
        <p>
          JIT：对 flow-matching 目标做少量修改，让 Diffusion 模型自己学压缩，根本不需要 VAE。
        </p>
        <p>
          目前效果还不如最好的对齐 VAE 方案。但 Linum 团队直觉认为：JIT 也在过拟合噪声（程度更轻），如果让它显式学习 DINO 式语义表征，可能会超越现有方法。
        </p>
        <div class="refs"><a href="https://arxiv.org/abs/2511.13720">JIT</a></div>
      </div>
    </div>
  </section>

  <!-- ═══════════════════════ TAKEAWAY ═══════════════════════ -->
  <div class="takeaway">
    <div class="thesis-label">Takeaway</div>
    <p>
      VAE 的目标是<strong>"有意义的有损压缩"</strong>——丢掉噪声，保留语义结构，让下游模型能学到东西。
    </p>
  </div>

  <footer>
    原文 by <a href="https://www.linum.ai/field-notes/vae-reconstruction-vs-generation" target="_blank">Linum AI</a>
  </footer>

</div>

<script>
window.addEventListener('scroll', () => {
  const h = document.documentElement;
  const pct = (h.scrollTop / (h.scrollHeight - h.clientHeight)) * 100;
  document.getElementById('progress').style.width = Math.min(pct, 100) + '%';
}, { passive: true });

const toc = document.getElementById('toc');
if (toc) {
  const links = [...toc.querySelectorAll('a')];
  const targets = links.map(a => document.querySelector(a.getAttribute('href'))).filter(Boolean);
  const update = () => {
    let current = '';
    for (const t of targets) {
      if (t.getBoundingClientRect().top <= 140) current = t.id;
    }
    links.forEach(a => a.classList.toggle('active', a.getAttribute('href') === '#' + current));
  };
  window.addEventListener('scroll', update, { passive: true });
  update();
}
</script>

<script defer src="https://cloud.umami.is/script.js" data-website-id="920ac93c-222f-4ac4-9de2-f7cf2d3de4cd"></script>
</body>
</html>
