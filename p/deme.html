<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Decouple-Then-Merge (DeMe)：将扩散模型训练视为多任务学习，解耦不同时间步的梯度冲突，再合并回单一模型——零额外推理成本，6 个基准显著提升。">
<title>Decouple-Then-Merge</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
<style>

  :root {
    --bg: #FAF8F5;
    --surface: #FFFFFF;
    --text-1: #1D1B18;
    --text-2: #5C5750;
    --text-3: #9B958C;
    --border: #E8E3DB;
    --accent: #B8714A;
    --blue: #7C6B5B;
    --blue-soft: #F5F0EB;
    --amber: #B8864A;
    --amber-bg: #FBF6F0;
    --red: #B85C4A;
    --red-bg: #FBF2F0;
    --green: #5A8A6E;
    --green-bg: #F0F6F2;
    --purple: #7B6892;
    --purple-bg: #F0ECF5;
    --mono: 'JetBrains Mono', 'SF Mono', monospace;
    --sans: 'Inter', -apple-system, 'PingFang SC', 'Noto Sans SC', sans-serif;
    --content-w: 680px;
    --wide-w: 780px;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }
  html { font-size: 16px; }
  @media (prefers-reduced-motion: no-preference) { html { scroll-behavior: smooth; } }

  body {
    font-family: var(--sans);
    background: var(--bg);
    color: var(--text-1);
    line-height: 1.85;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
  }

  #progress {
    position: fixed; top: 0; left: 0; height: 2px;
    background: var(--accent); z-index: 999;
    transition: width 80ms linear; pointer-events: none;
  }

  .container { max-width: var(--content-w); margin: 0 auto; padding: 0 24px; }
  .wide { max-width: var(--wide-w); }

  header {
    padding: 100px 0 48px;
    border-bottom: 1px solid var(--border);
    margin-bottom: 64px;
    animation: enter 0.6s ease both;
  }
  @keyframes enter {
    from { opacity: 0; transform: translateY(8px); }
  }
  header .eyebrow {
    font-size: 0.7rem; font-weight: 600;
    letter-spacing: 0.12em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 20px;
  }
  header h1 {
    font-size: 2.2rem; font-weight: 700;
    line-height: 1.25; letter-spacing: -0.03em;
    margin-bottom: 24px; max-width: 560px;
  }
  header h1 .sym { color: var(--accent); }
  header .subtitle {
    font-size: 1rem; color: var(--text-2);
    line-height: 1.9; max-width: 580px;
  }
  header .meta {
    margin-top: 28px; display: flex; gap: 24px;
    font-size: 0.75rem; color: var(--text-3); flex-wrap: wrap;
  }
  header .meta a {
    color: var(--text-3); text-decoration: none;
    border-bottom: 1px solid var(--border);
    transition: all 0.15s;
  }
  header .meta a:hover { color: var(--text-1); border-color: var(--text-1); }

  .thesis {
    background: #2C2520; color: #F5F0EB;
    padding: 36px 40px; border-radius: 16px;
    margin-bottom: 72px; position: relative;
  }
  .thesis .thesis-label {
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.14em; text-transform: uppercase;
    opacity: 0.45; margin-bottom: 14px;
  }
  .thesis p {
    font-size: 1.05rem; line-height: 1.85;
    font-weight: 400;
  }
  .thesis strong { color: #E8B87A; font-weight: 600; }
  .thesis .evidence {
    margin-top: 20px; padding-top: 18px;
    border-top: 1px solid rgba(255,255,255,0.1);
    font-size: 0.82rem; opacity: 0.65; line-height: 1.7;
  }
  .thesis .evidence em { font-style: normal; opacity: 0.85; }

  section { margin-bottom: 72px; }
  .section-num {
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.12em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 8px;
  }
  section > h2 {
    font-size: 1.5rem; font-weight: 700;
    line-height: 1.3; letter-spacing: -0.02em;
    margin-bottom: 6px;
  }
  section > .section-hook {
    font-size: 0.85rem; color: var(--text-3);
    margin-bottom: 24px; line-height: 1.6;
  }
  h3 {
    font-size: 1.1rem; font-weight: 600;
    margin: 40px 0 12px; letter-spacing: -0.01em;
  }
  p { margin-bottom: 18px; }
  p:last-child { margin-bottom: 0; }

  a { color: var(--accent); text-decoration: none; }
  a:hover { text-decoration: underline; }

  strong { font-weight: 600; }
  em { font-style: italic; color: var(--text-2); }

  .sep {
    height: 1px; background: var(--border);
    margin: 72px 0; border: none;
  }

  .note {
    padding: 20px 24px; border-radius: 12px;
    margin: 24px 0; font-size: 0.88rem; line-height: 1.8;
    border-left: 3px solid;
  }
  .note-label {
    font-size: 0.65rem; font-weight: 700;
    letter-spacing: 0.08em; text-transform: uppercase;
    margin-bottom: 6px;
  }
  .note-insight  { background: var(--amber-bg); border-color: var(--amber); }
  .note-insight .note-label { color: var(--amber); }
  .note-problem  { background: var(--red-bg);   border-color: var(--red); }
  .note-problem .note-label { color: var(--red); }
  .note-ok       { background: var(--green-bg); border-color: var(--green); }
  .note-ok .note-label { color: var(--green); }
  .note-neutral  { background: #F5F2ED; border-color: var(--border); color: var(--text-2); }
  .note-neutral .note-label { color: var(--text-3); }

  .versus {
    display: grid; grid-template-columns: 1fr auto 1fr;
    gap: 0; margin: 24px 0; font-size: 0.85rem;
    border: 1px solid var(--border); border-radius: 14px;
    overflow: hidden;
  }
  .versus .v-side { padding: 20px 24px; }
  .versus .v-label {
    font-size: 0.62rem; font-weight: 700;
    letter-spacing: 0.08em; text-transform: uppercase;
    margin-bottom: 6px;
  }
  .versus .v-left  { background: var(--red-bg); }
  .versus .v-left .v-label  { color: var(--red); }
  .versus .v-right { background: var(--green-bg); }
  .versus .v-right .v-label { color: var(--green); }
  .versus .v-mid {
    display: flex; align-items: center; justify-content: center;
    padding: 0 4px; font-weight: 700; color: var(--text-3);
    background: var(--bg); font-size: 0.75rem;
  }

  .causal {
    margin: 24px 0; padding: 0; list-style: none;
    counter-reset: cause;
  }
  .causal li {
    counter-increment: cause; position: relative;
    padding: 8px 0 8px 44px; font-size: 0.9rem;
    line-height: 1.75;
  }
  .causal li::before {
    content: counter(cause); position: absolute;
    left: 0; top: 10px;
    width: 28px; height: 28px; border-radius: 50%;
    background: #2C2520; color: #F5F0EB;
    font-size: 0.7rem; font-weight: 700;
    display: flex; align-items: center; justify-content: center;
  }
  .causal li + li { border-top: 1px dashed var(--border); }

  .pipeline {
    display: flex; align-items: center; justify-content: center;
    gap: 0; margin: 28px 0; flex-wrap: wrap;
    font-size: 0.82rem;
  }
  .pipe-node {
    padding: 10px 18px; border: 1px solid var(--border);
    background: var(--surface); font-weight: 500;
    text-align: center; white-space: nowrap;
  }
  .pipe-node:first-child { border-radius: 8px 0 0 8px; }
  .pipe-node:last-child { border-radius: 0 8px 8px 0; }
  .pipe-node + .pipe-node { border-left: none; }
  .pipe-node.is-decouple { background: var(--red-bg); border-color: #D4B8B0; }
  .pipe-node.is-finetune { background: var(--amber-bg); border-color: #DCC9A8; font-weight: 700; }
  .pipe-node.is-merge { background: var(--green-bg); border-color: #B8D4C0; font-weight: 700; }
  .pipe-node.is-pretrain { background: var(--blue-soft); border-color: #DDD5CB; }

  details {
    margin: 20px 0; border: 1px solid var(--border);
    border-radius: 12px; overflow: hidden;
  }
  details summary {
    padding: 14px 20px; cursor: pointer;
    font-size: 0.82rem; font-weight: 500;
    color: var(--text-2); background: #F5F2ED;
    user-select: none; list-style: none;
    transition: background 0.15s;
  }
  details summary:hover { background: #EDE9E3; }
  details summary::-webkit-details-marker { display: none; }
  details summary::before { content: '+ '; font-weight: 700; color: var(--text-3); }
  details[open] summary::before { content: '− '; }
  details .expand-body {
    padding: 18px 20px; font-size: 0.85rem;
    line-height: 1.8; color: var(--text-2);
  }

  .stat-grid {
    display: grid; grid-template-columns: 1fr 1fr 1fr;
    gap: 12px; margin: 24px 0;
  }
  @media (max-width: 600px) { .stat-grid { grid-template-columns: 1fr; } }
  .stat-item {
    padding: 20px; background: var(--surface);
    border: 1px solid var(--border); border-radius: 12px;
    text-align: center;
  }
  .stat-num {
    font-size: 1.6rem; font-weight: 700;
    letter-spacing: -0.03em; color: var(--accent);
    margin-bottom: 4px;
  }
  .stat-label {
    font-size: 0.72rem; color: var(--text-3);
    line-height: 1.5;
  }

  .technique-grid {
    display: grid; grid-template-columns: 1fr 1fr 1fr;
    gap: 16px; margin: 28px 0;
  }
  @media (max-width: 600px) { .technique-grid { grid-template-columns: 1fr; } }
  .technique {
    padding: 24px; background: var(--surface);
    border: 1px solid var(--border); border-radius: 14px;
    transition: border-color 0.2s, box-shadow 0.2s;
  }
  .technique:hover { border-color: #D0C8BD; box-shadow: 0 2px 12px rgba(0,0,0,0.04); }
  .technique-tag {
    font-size: 0.6rem; font-weight: 700;
    letter-spacing: 0.1em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 8px;
  }
  .technique h4 {
    font-size: 0.95rem; font-weight: 700;
    margin-bottom: 10px; line-height: 1.4;
  }
  .technique p { font-size: 0.82rem; color: var(--text-2); line-height: 1.7; margin-bottom: 0; }

  table {
    width: 100%; border-collapse: collapse;
    margin: 24px 0; font-size: 0.82rem;
  }
  thead th {
    text-align: left; padding: 10px 14px;
    font-size: 0.7rem; font-weight: 600;
    letter-spacing: 0.04em; text-transform: uppercase;
    color: var(--text-3); border-bottom: 2px solid var(--border);
  }
  tbody td {
    padding: 10px 14px; border-bottom: 1px solid var(--border);
    vertical-align: top;
  }
  tbody tr:last-child td { border-bottom: none; }
  tr.row-ok td { background: var(--green-bg); }
  .badge {
    display: inline-block; font-size: 0.65rem; font-weight: 600;
    padding: 2px 8px; border-radius: 100px;
  }
  .badge-best { background: var(--green-bg); color: var(--green); }
  .badge-good { background: var(--amber-bg); color: var(--amber); }
  .badge-base { background: #F5F2ED; color: var(--text-3); }

  .formula {
    margin: 20px 0; padding: 18px 24px;
    background: var(--surface); border: 1px solid var(--border);
    border-radius: 12px; font-size: 0.88rem;
    text-align: center; line-height: 2;
    font-family: var(--mono);
    overflow-x: auto;
  }
  .formula .label {
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.08em; text-transform: uppercase;
    color: var(--text-3); margin-bottom: 4px;
    font-family: var(--sans);
    text-align: left;
  }
  .formula .math {
    font-size: 0.92rem; color: var(--text-1);
  }

  .heatmap-desc {
    display: grid; grid-template-columns: auto 1fr;
    gap: 20px; margin: 24px 0; padding: 20px 24px;
    background: var(--surface); border: 1px solid var(--border);
    border-radius: 14px; align-items: center;
  }
  .heatmap-visual {
    width: 120px; height: 120px; border-radius: 8px;
    background: linear-gradient(135deg, #4A7B5A 0%, #B8864A 30%, #B85C4A 60%, #2C2520 100%);
    position: relative; display: flex; align-items: center; justify-content: center;
    font-size: 0.6rem; color: rgba(255,255,255,0.7);
    font-family: var(--mono);
  }
  .heatmap-visual::after {
    content: 'cos sim'; position: absolute; bottom: 6px; right: 8px;
    font-size: 0.55rem; opacity: 0.6;
  }
  .heatmap-text { font-size: 0.85rem; line-height: 1.75; }
  .heatmap-text strong { font-weight: 600; }

  code {
    font-family: var(--mono); font-size: 0.82em;
    background: #F0EDE8; padding: 2px 7px; border-radius: 5px;
  }

  .takeaway {
    background: #2C2520; color: #F5F0EB;
    padding: 36px 40px; border-radius: 16px;
    margin: 72px 0 48px;
  }
  .takeaway .thesis-label {
    font-size: 0.65rem; font-weight: 600;
    letter-spacing: 0.14em; text-transform: uppercase;
    opacity: 0.45; margin-bottom: 12px;
  }
  .takeaway p { font-size: 1.05rem; line-height: 1.85; }
  .takeaway strong { color: #8EC5A0; font-weight: 600; }

  .topbar {
    position: fixed; top: 2px; left: 0; right: 0;
    z-index: 100; padding: 10px 24px;
    display: flex; justify-content: space-between; align-items: center;
    font-size: 0.72rem;
    background: rgba(250,248,245,0.85);
    backdrop-filter: blur(12px); -webkit-backdrop-filter: blur(12px);
    border-bottom: 1px solid rgba(232,227,219,0.6);
  }
  .topbar a {
    color: var(--text-3); text-decoration: none;
    transition: color 0.15s;
  }
  .topbar a:hover { color: var(--text-1); }
  .topbar .home-link { font-weight: 500; letter-spacing: 0.02em; }
  .topbar .site-name { color: var(--text-3); font-weight: 400; }

  footer {
    text-align: center; padding: 48px 0 64px;
    font-size: 0.72rem; color: var(--text-3);
  }
  footer a { color: var(--text-3); border-bottom: 1px solid var(--border); text-decoration: none; }
  footer a:hover { color: var(--text-1); }

  a:focus-visible,
  details summary:focus-visible {
    outline: 2px solid var(--accent);
    outline-offset: 3px;
    border-radius: 2px;
  }

  @media (prefers-reduced-motion: reduce) {
    header { animation: none; }
  }

  @media (max-width: 600px) {
    header h1 { font-size: 1.6rem; }
    .thesis, .takeaway { padding: 28px 24px; }
    .versus { grid-template-columns: 1fr; }
    .versus .v-mid {
      padding: 8px; border-top: 1px solid var(--border);
      border-bottom: 1px solid var(--border);
    }
    .stat-grid { grid-template-columns: 1fr 1fr; }
    .technique-grid { grid-template-columns: 1fr; }
    .heatmap-desc { grid-template-columns: 1fr; }
    .heatmap-visual { width: 100%; height: 80px; }
  }

  nav.toc {
    position: fixed; top: 100px;
    left: max(20px, calc((100vw - var(--content-w)) / 2 - 240px));
    width: 200px; font-size: 0.7rem; line-height: 1.6;
    z-index: 50;
  }
  @media (max-width: 1100px) { nav.toc { display: none; } }
  nav.toc a {
    display: block; padding: 4px 0 4px 14px;
    border-left: 1px solid var(--border);
    color: var(--text-3); text-decoration: none;
    transition: all 0.15s;
  }
  nav.toc a:hover, nav.toc a.active {
    color: var(--text-1); border-color: var(--text-1);
  }
  nav.toc .indent { padding-left: 26px; font-size: 0.65rem; }

  .landscape-grid {
    display: grid; grid-template-columns: 1fr 1fr;
    gap: 12px; margin: 24px 0;
  }
  @media (max-width: 600px) { .landscape-grid { grid-template-columns: 1fr; } }
  .landscape-card {
    padding: 20px; background: var(--surface);
    border: 1px solid var(--border); border-radius: 12px;
    text-align: center;
  }
  .landscape-card .lc-visual {
    height: 80px; border-radius: 8px; margin-bottom: 10px;
    display: flex; align-items: center; justify-content: center;
    font-family: var(--mono); font-size: 0.7rem; color: var(--text-3);
  }
  .landscape-card .lc-label {
    font-size: 0.72rem; font-weight: 600; margin-bottom: 4px;
  }
  .landscape-card .lc-desc {
    font-size: 0.75rem; color: var(--text-2); line-height: 1.6;
  }
  .lc-flat { background: linear-gradient(180deg, #E8E3DB 0%, #E8E3DB 100%); }
  .lc-steep { background: linear-gradient(180deg, #D4B8B0 0%, #FBF6F0 40%, #D4B8B0 70%, #FBF2F0 100%); }

  .fig {
    margin: 28px 0; border: 1px solid var(--border);
    border-radius: 14px; overflow: hidden;
    background: var(--surface);
  }
  .fig img {
    width: 100%; display: block;
  }
  .fig-caption {
    padding: 14px 20px; font-size: 0.75rem;
    color: var(--text-3); line-height: 1.65;
    border-top: 1px solid var(--border);
  }
  .fig-caption strong { color: var(--text-2); font-weight: 600; }
  .fig-wide {
    max-width: var(--wide-w);
    margin-left: calc((var(--content-w) - var(--wide-w)) / 2);
  }
  @media (max-width: 840px) {
    .fig-wide { max-width: 100%; margin-left: 0; }
  }
</style>
</head>
<body>

<div class="topbar">
  <a class="home-link" href="/">← 首页</a>
  <span class="site-name">pinyu.ai</span>
</div>

<div id="progress" style="width:0%"></div>

<nav class="toc" id="toc">
  <a href="#core-thesis">核心论点</a>
  <a href="#conflict">梯度冲突问题</a>
  <a href="#framework">DeMe 框架</a>
  <a class="indent" href="#decouple">解耦训练</a>
  <a class="indent" href="#techniques">三项关键技术</a>
  <a class="indent" href="#merge">模型合并</a>
  <a href="#results">实验结果</a>
  <a class="indent" href="#unconditional">无条件生成</a>
  <a class="indent" href="#t2i">文生图</a>
  <a class="indent" href="#qualitative">定性对比</a>
  <a class="indent" href="#ablation">消融实验</a>
  <a href="#why-works">为什么有效</a>
  <a href="#takeaway-section">Takeaway</a>
</nav>

<div class="container">

  <header>
    <div class="eyebrow">CVPR 2025 · Paper Deep Dive</div>
    <h1>Decouple<span class="sym">-</span>Then<span class="sym">-</span>Merge</h1>
    <p class="subtitle">
      扩散模型的不同去噪时间步之间存在梯度冲突。DeMe 提出：先解耦训练，再合并参数——将多任务学习的负迁移转化为正收益，零额外推理成本，6 个基准显著提升生成质量。
    </p>
    <div class="meta">
      <span>Ma et al. · SJTU / THU / Shanghai AI Lab · CVPR 2025</span>
      <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Decouple-Then-Merge_Finetune_Diffusion_Models_as_Multi-Task_Learning_CVPR_2025_paper.pdf" target="_blank">论文 PDF</a>
    </div>
  </header>

  <!-- ═══════════════════════ THESIS ═══════════════════════ -->
  <div class="thesis" id="core-thesis">
    <div class="thesis-label">Core Thesis</div>
    <p>
      扩散模型在所有时间步共享参数。但不同时间步的去噪任务本质不同：大时间步生成低频内容（构图、结构），小时间步生成高频细节。<strong>共享参数 = 强迫一个模型同时做 N 个互相冲突的任务 = 梯度互相拉扯 = 谁也做不好。</strong>
    </p>
    <div class="evidence">
      <em>实证</em>：CIFAR10 上不相邻时间步的梯度余弦相似度接近零甚至为负。DeMe 解耦后再合并：FID 从 4.42 降至 3.51（-21%），LSUN-Church 从 10.69 降至 7.27（-32%）——零额外推理成本。
    </div>
  </div>

  <!-- ═══════════════════════ §1 GRADIENT CONFLICT ═══════════════════════ -->
  <section id="conflict">
    <div class="section-num">01</div>
    <h2>梯度冲突：被忽视的训练瓶颈</h2>
    <p class="section-hook">扩散模型训练的核心矛盾——为什么共享参数既是优势又是诅咒</p>

    <p>
      扩散模型的训练本质上是在做<strong>多任务学习</strong>：从 t=0 到 t=T 的每个时间步都是一个独立的去噪任务，但它们共享同一组模型参数。共享的好处显而易见——训练效率高，不同任务间可以互相借力。
    </p>
    <p>
      但代价呢？论文通过计算不同时间步梯度之间的余弦相似度，揭示了一个被忽视的事实：
    </p>

    <div class="fig fig-wide">
      <img src="img/deme/fig1_gradient.png" alt="Figure 1: Gradient cosine similarity heatmap between different timesteps" loading="lazy">
      <div class="fig-caption">
        <strong>Figure 1</strong>：(a) CIFAR10 上不同时间步梯度的余弦相似度热力图——对角线附近（相邻时间步）相似度高，远离对角线则迅速衰减至零甚至为负，表明梯度冲突。右侧直方图对比了 t∈[0,1000] 和 t∈[0,250] 的梯度相似度分布。(b)(c) 传统范式（所有时间步共享一个模型）vs DeMe 范式（解耦为 N 个时间步区间分别训练）。
      </div>
    </div>

    <div class="note note-problem">
      <div class="note-label">关键认知</div>
      这不是"训练不够充分"的问题——即使训练到收敛，梯度冲突仍然存在。pretrained 模型看似收敛（整体梯度为零），但实际上不同时间步的梯度<strong>互相抵消</strong>后才等于零。模型停在了一个折中点，而非最优点。
    </div>

    <h3>不同时间步到底在做什么？</h3>
    <p>
      已有研究（Fang et al.）表明，扩散模型在不同时间步承担本质不同的任务：
    </p>

    <div class="versus">
      <div class="v-side v-left">
        <div class="v-label">大时间步 t → T</div>
        噪声多，信号少。模型生成<strong>低频信息</strong>：构图、基本形状、全局色彩。类似"画草图"。
      </div>
      <div class="v-mid">VS</div>
      <div class="v-side v-right">
        <div class="v-label">小时间步 t → 0</div>
        噪声少，信号清晰。模型生成<strong>高频细节</strong>：纹理、边缘、精细结构。类似"上油彩"。
      </div>
    </div>

    <p>
      让一个画家同时学"画草图"和"上油彩"，梯度告诉我们：这两项技能的优化方向是冲突的。传统方案——loss 重加权——只能调节各任务的"音量"，但解决不了它们<strong>方向上的矛盾</strong>。
    </p>

    <details>
      <summary>与多任务学习的对应关系</summary>
      <div class="expand-body">
        多任务学习中的经典问题——<strong>负迁移</strong>（Negative Transfer）：联合训练多个任务时，某些任务的性能比单独训练更差。扩散模型的时间步共享训练完美复现了这个问题：每个时间步是一个"任务"，共享参数是"联合训练"，梯度冲突是"负迁移"的直接表现。<br><br>
        传统解法如 loss 重加权（Min-SNR、P2 Weighting 等）相当于调节各任务的权重，但无法消除梯度方向上的冲突——只是让某些任务"喊得更大声"，不改变它们"往不同方向喊"的事实。
      </div>
    </details>
  </section>

  <!-- ═══════════════════════ §2 FRAMEWORK ═══════════════════════ -->
  <section id="framework">
    <div class="section-num">02</div>
    <h2>DeMe 框架：解耦训练，参数合并</h2>
    <p class="section-hook">核心思路——把一个多任务问题拆成 N 个单任务，训完再融合</p>

    <div class="pipeline">
      <div class="pipe-node is-pretrain">预训练模型 θ</div>
      <div class="pipe-node is-decouple">解耦为 N 份</div>
      <div class="pipe-node is-finetune">各自微调</div>
      <div class="pipe-node is-merge">参数空间合并</div>
      <div class="pipe-node is-pretrain">单一模型 θ<sub>merged</sub></div>
    </div>

    <p>
      DeMe 的框架极其优雅：从预训练模型出发，拆分时间步范围，各自微调，最后在参数空间合并回一个模型。推理时仍然是一个模型、没有任何额外开销——但生成质量显著提升。
    </p>

    <div class="fig fig-wide">
      <img src="img/deme/fig3_pipeline.png" alt="Figure 3: DeMe framework pipeline" loading="lazy">
      <div class="fig-caption">
        <strong>Figure 3</strong>：DeMe 框架全景。微调阶段引入三项技术：Consistency Loss 保持与原始模型的一致性；Probabilistic Sampling 以一定概率从非对应区间采样防止遗忘；Channel-wise Projection 通过 C×C 矩阵捕捉通道维度的特征差异。微调后通过 Task Vector 加权合并为单一模型。
      </div>
    </div>

    <!-- ── Decouple ── -->
    <h3 id="decouple">Step 1：解耦训练</h3>
    <p>
      将 [0, T) 等分为 N 个不重叠的时间步区间：
    </p>

    <div class="formula">
      <div class="label">时间步划分</div>
      <div class="math">[0, T) → {[0, T/N), [T/N, 2T/N), ..., [(N-1)T/N, T)}</div>
    </div>

    <p>
      每个区间对应一个独立微调的模型 ε<sub>θᵢ</sub>，<strong>只用该区间内的时间步计算 loss</strong>。这样，不同区间的梯度永远不会在同一模型的参数上累加——冲突被物理隔离了。
    </p>

    <div class="note note-insight">
      <div class="note-label">关键洞察 · 临界点逃逸</div>
      预训练模型在完整时间步范围 [0, T) 上已经收敛到一个"临界点"（梯度为零）。但当你只看某个子区间时，这个点并<strong>不是局部最优</strong>——模型周围有明确的梯度方向和更低的 loss 值。解耦训练让模型从这个折中的"假收敛"中逃出来，在各自的子区间上继续优化。
    </div>

    <!-- ── Techniques ── -->
    <h3 id="techniques">Step 2：三项训练技术</h3>
    <p>
      纯粹的解耦会带来新问题：每个微调模型只见过一部分时间步，可能遗忘其他时间步的知识，或过拟合到自己的子区间。论文引入三项技术来平衡"隔离冲突"与"保留共享"：
    </p>

    <div class="technique-grid">
      <div class="technique">
        <div class="technique-tag">技术 A</div>
        <h4>Channel-wise Projection</h4>
        <p>
          在中间特征上加一个可学习的 C×C 投影矩阵（初始化为单位矩阵）。论文发现微调前后的激活差异<strong>主要集中在通道维度</strong>而非空间维度，这个投影层直接捕捉通道映射的变化。参数量仅占模型的 1.06%。
        </p>
      </div>
      <div class="technique">
        <div class="technique-tag">技术 B</div>
        <h4>Consistency Loss</h4>
        <p>
          微调时加一项额外损失：让微调后模型的输出不要偏离原始预训练模型太远。这像一根"弹簧"——允许模型在子区间上优化，但防止它走得太远、丢失全局知识。
        </p>
      </div>
      <div class="technique">
        <div class="technique-tag">技术 C</div>
        <h4>Probabilistic Sampling</h4>
        <p>
          以概率 (1-p) 从对应子区间采样时间步，以概率 p 从完整范围 [0, T) 采样。主攻自己的区间，但偶尔"回顾"其他区间的知识，防止灾难性遗忘。
        </p>
      </div>
    </div>

    <details>
      <summary>三项技术的消融贡献</summary>
      <div class="expand-body">
        在 CIFAR10 上（N=8，100-step DDIM），逐项叠加的效果：<br><br>
        <strong>传统训练（N=1）</strong>：FID 4.40（基线）<br>
        <strong>+ 解耦为 8 份 + Probabilistic Sampling</strong>：FID 4.32（-0.08）<br>
        <strong>+ Consistency Loss</strong>：FID 4.27（-0.05）<br>
        <strong>+ Channel-wise Projection</strong>：FID 3.87（-0.40）<br><br>
        Channel-wise Projection 的贡献最大，但它必须在解耦（N>1）的前提下才有效——单独在 N=1 时加这个投影反而让 FID 变差（4.40→4.45），因为通道差异在所有时间步混杂时过于复杂，投影矩阵无法有效学习。
      </div>
    </details>

    <!-- ── Merge ── -->
    <h3 id="merge">Step 3：参数空间合并</h3>
    <p>
      微调后得到 N 个模型 {θ₁, θ₂, ..., θ<sub>N</sub>}。直接集成推理（ensemble）需要 N 倍存储——不实际。论文采用<strong>任务向量</strong>（Task Arithmetic）做参数合并：
    </p>

    <div class="formula">
      <div class="label">Task Vector Merging</div>
      <div class="math">τᵢ = θᵢ − θ &nbsp;&nbsp;(task vector)<br>θ_merged = θ + Σ wᵢ · τᵢ</div>
    </div>

    <p>
      每个 task vector τᵢ 编码了"第 i 个区间相对于预训练模型学到的增量知识"。加权求和后叠加回预训练模型，得到一个融合了所有区间知识的单一模型。权重 wᵢ 通过网格搜索确定。
    </p>

    <div class="note note-ok">
      <div class="note-label">核心优势</div>
      合并后的模型<strong>和原始模型参数量完全一致</strong>——相同的计算量、相同的存储、相同的推理流程。所有改进都是"免费的"。这是 DeMe 最具工程吸引力的特性：只需在微调阶段多花 N 倍计算，之后的整个生命周期没有任何额外成本。
    </div>

    <div class="note note-insight">
      <div class="note-label">反直觉 · 合并 > 集成</div>
      在 LSUN-Church 上，模型集成（ensemble）将 FID 从 10.69 降至 9.57，但参数合并将 FID 降至 <strong>7.27</strong>——合并竟然比集成效果更好。这是因为 task vector 的加权组合不只是取平均，而是在参数空间中找到了一个<strong>比任何单个微调模型都更优的点</strong>。
    </div>
  </section>

  <hr class="sep">

  <!-- ═══════════════════════ §3 RESULTS ═══════════════════════ -->
  <section id="results">
    <div class="section-num">03</div>
    <h2>实验结果：6 个基准的硬数据</h2>
    <p class="section-hook">不是边际改进——是在成熟基线上的显著跳跃</p>

    <h3 id="unconditional">无条件图像生成（DDPM）</h3>

    <table>
      <thead>
        <tr><th>方法</th><th>CIFAR10 FID↓</th><th>LSUN-Church FID↓</th><th>LSUN-Bedroom FID↓</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>预训练基线 <span class="badge badge-base">DDPM</span></td>
          <td>4.42</td><td>10.69</td><td>6.46</td>
        </tr>
        <tr>
          <td>Min-SNR-γ</td>
          <td>5.77 <em>(+1.35)</em></td><td>10.82</td><td>6.41</td>
        </tr>
        <tr>
          <td>P2 Weighting</td>
          <td>5.63 <em>(+1.21)</em></td><td>10.77</td><td>6.53</td>
        </tr>
        <tr>
          <td>ANT-UW <span class="badge badge-base">最强基线</span></td>
          <td>4.21</td><td>10.43</td><td>6.48</td>
        </tr>
        <tr>
          <td>DeMe (集成) <span class="badge badge-good">N 个模型</span></td>
          <td>3.79 <em>(-0.63)</em></td><td>9.57</td><td>5.87</td>
        </tr>
        <tr class="row-ok">
          <td>DeMe (合并) <span class="badge badge-best">1 个模型</span></td>
          <td><strong>3.51</strong> <em>(-0.91)</em></td><td><strong>7.27</strong> <em>(-3.42)</em></td><td><strong>5.84</strong> <em>(-0.62)</em></td>
        </tr>
      </tbody>
    </table>

    <div class="stat-grid">
      <div class="stat-item">
        <div class="stat-num">-0.91</div>
        <div class="stat-label">CIFAR10<br>FID 改进</div>
      </div>
      <div class="stat-item">
        <div class="stat-num">-3.42</div>
        <div class="stat-label">LSUN-Church<br>FID 改进</div>
      </div>
      <div class="stat-item">
        <div class="stat-num">-0.62</div>
        <div class="stat-label">LSUN-Bedroom<br>FID 改进</div>
      </div>
    </div>

    <div class="note note-problem">
      <div class="note-label">对比基线的失败</div>
      注意 loss 重加权方法（Min-SNR、P2 Weighting）在 CIFAR10 上<strong>反而让 FID 变差</strong>。同样的微调预算（80K iterations），调权重只能调音量、不能消除方向冲突——有时调错权重甚至恶化表现。
    </div>

    <h3 id="t2i">文生图（Stable Diffusion）</h3>

    <table>
      <thead>
        <tr><th>方法</th><th>COCO FID↓</th><th>COCO CLIP↑</th><th>ImageNet FID↓</th><th>PartiPrompts CLIP↑</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>Stable Diffusion <span class="badge badge-base">基线</span></td>
          <td>13.42</td><td>29.88</td><td>27.62</td><td>29.78</td>
        </tr>
        <tr>
          <td>ANT-UW</td>
          <td>13.17</td><td>29.94</td><td>26.91</td><td>29.98</td>
        </tr>
        <tr class="row-ok">
          <td>DeMe (合并) <span class="badge badge-best">最优</span></td>
          <td><strong>13.06</strong></td><td><strong>30.11</strong></td><td><strong>27.23</strong></td><td><strong>29.98</strong></td>
        </tr>
      </tbody>
    </table>

    <p>
      在文生图任务上，DeMe 合并方案的亮点是<strong>同时提升了图像质量和文本对齐度</strong>：COCO 上 FID 降了 0.36 的同时 CLIP Score 提了 0.23——这两者通常是此消彼长的。集成方案虽然 FID 降幅更大（-0.64），但 CLIP Score 反而下降了 0.03。
    </p>

    <div class="note note-ok">
      <div class="note-label">文生图的微妙之处</div>
      合并方案在<strong>文本对齐度</strong>上优于集成方案。可能原因：集成在不同时间步切换模型时引入了不一致性——模型 A 画草图时理解的语义和模型 B 上细节时的理解可能不完全对齐。合并后的单一模型保持了全局一致的语义理解。
    </div>

    <h3 id="qualitative">定性对比：微调前 vs 后</h3>

    <div class="fig fig-wide">
      <img src="img/deme/cvpr2025_quality1.png" alt="Qualitative comparison: before vs after finetuning with DeMe" loading="lazy">
      <div class="fig-caption">
        <strong>Stable Diffusion 文生图对比</strong>：上方为微调前（原始 SD），下方为 DeMe 微调后。注意文本对齐度的提升——DeMe 能更准确地捕捉 prompt 中的细节描述（如"小木屋"、"野花"、"水花"等被忽略的元素），同时生成更细腻的纹理和光影。
      </div>
    </div>

    <div class="fig fig-wide">
      <img src="img/deme/cvpr2025_quality2.png" alt="More qualitative comparison on unconditional generation" loading="lazy">
      <div class="fig-caption">
        <strong>无条件生成对比（LSUN）</strong>：左为原始模型，右为 DeMe 合并后模型。结构更清晰，细节更丰富，色彩更自然。
      </div>
    </div>

    <h3 id="ablation">消融实验</h3>

    <table>
      <thead>
        <tr><th>N (分组数)</th><th>Channel Proj.</th><th>Prob. Sampling</th><th>Consist. Loss</th><th>FID↓</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>1</td><td>✗</td><td>✗</td><td>✗</td><td>4.40 <span class="badge badge-base">传统训练</span></td>
        </tr>
        <tr>
          <td>1</td><td>✓</td><td>✗</td><td>✗</td><td>4.45 <em>(+0.05, 变差)</em></td>
        </tr>
        <tr>
          <td>8</td><td>✗</td><td>✓</td><td>✗</td><td>4.32</td>
        </tr>
        <tr>
          <td>8</td><td>✗</td><td>✓</td><td>✓</td><td>4.27</td>
        </tr>
        <tr class="row-ok">
          <td>8</td><td>✓</td><td>✓</td><td>✓</td><td><strong>3.87</strong> <span class="badge badge-best">全部启用</span></td>
        </tr>
      </tbody>
    </table>

    <ol class="causal">
      <li><strong>解耦是必要条件</strong>：Channel-wise Projection 在 N=1 时无效甚至有害，但在 N=8 时贡献最大（FID -0.40）。原因：不解耦时所有时间步的通道差异混杂在一起，C×C 矩阵学不到有意义的映射。</li>
      <li><strong>Probabilistic Sampling 和 Consistency Loss</strong> 各自贡献 0.08 和 0.05 的 FID 改进——它们的作用是防止过拟合到子区间和遗忘全局知识。</li>
      <li><strong>全部叠加时有协同效应</strong>：总改进 0.53，大于各项之和——三项技术相互增强。</li>
    </ol>
  </section>

  <hr class="sep">

  <!-- ═══════════════════════ §4 WHY WORKS ═══════════════════════ -->
  <section id="why-works">
    <div class="section-num">04</div>
    <h2>为什么有效：Loss Landscape 的视角</h2>
    <p class="section-hook">从损失地形和任务向量两个视角，理解 DeMe 的底层机制</p>

    <h3>临界点逃逸</h3>
    <p>
      论文可视化了预训练模型在不同时间步范围上的 loss landscape（图 4）。两个关键发现：
    </p>

    <div class="fig fig-wide">
      <img src="img/deme/fig4_landscape.png" alt="Figure 4: Loss landscape visualization" loading="lazy">
      <div class="fig-caption">
        <strong>Figure 4</strong>：CIFAR10 上预训练模型在不同时间步范围的 loss landscape。蓝色=低 loss，红色=高 loss，等高线密度反映梯度大小。完整范围 t∈[0,1000) 时模型处于等高线稀疏的临界点（梯度为零）；但在子区间（如 t∈[0,250)）上，模型周围等高线密集——存在明确的优化方向。
      </div>
    </div>

    <p>
      这就是 DeMe 有效的底层原因：<strong>全局看似收敛的模型，在局部视角下远未收敛</strong>。解耦训练让模型在每个子区间上沿着各自的梯度方向独立优化，逃离折中的临界点。
    </p>

    <h3>Task Vector 分析</h3>
    <p>
      论文可视化了不同时间步范围的 task vector 幅度（图 6b）：
    </p>

    <div class="versus">
      <div class="v-side v-left">
        <div class="v-label">t ∈ [0, 500) — 小时间步</div>
        Task vector 幅度较小。微调前后参数变化不大——说明原始模型在这个范围已经学得不错。
      </div>
      <div class="v-mid">VS</div>
      <div class="v-side v-right">
        <div class="v-label">t ∈ [500, 1000) — 大时间步</div>
        Task vector 幅度显著更大。微调前后参数变化剧烈——说明<strong>原始模型在这个范围被严重欠优化</strong>。
      </div>
    </div>

    <div class="note note-insight">
      <div class="note-label">因果链</div>
      为什么大时间步被欠优化？因为原始的 SNR loss 权重在大时间步上<strong>天然偏低</strong>。当大时间步和小时间步的梯度发生冲突时，优化器偏向小时间步（因为它们的 loss 权重更高）——大时间步的优化被牺牲了。DeMe 解耦后，大时间步终于能"为自己发声"，不再被小时间步的梯度压制。
    </div>

    <h3>参数空间中的最优点</h3>
    <p>
      论文将两个 task vector 张成的平面上的 loss 进行可视化（图 6a），发现：
    </p>

    <div class="fig fig-wide">
      <img src="img/deme/fig6_taskvec.png" alt="Figure 6: Loss landscape for task vectors and box plot" loading="lazy">
      <div class="fig-caption">
        <strong>Figure 6</strong>：(a) Task vector 张成平面上的 loss landscape。预训练模型和微调模型都不在最优点——最优点位于 task vector 加权组合的方向上。等高线呈盆地状，变化光滑。(b) 不同时间步范围 task vector 幅度的箱线图：t∈[500,1000) 的幅度远大于 t∈[0,500)，说明大时间步在原始模型中被严重欠优化。
      </div>
    </div>

    <ol class="causal">
      <li>Loss 等高线呈<strong>盆地状</strong>——预训练模型和微调模型都不在最优点，但最优点<strong>就在它们中间</strong></li>
      <li>Task vector 的加权组合可以找到比任何单个模型都更好的参数——这就是为什么合并 > 集成</li>
      <li>Loss 变化相对光滑，为更高级的搜索方法（如进化搜索）留出了空间</li>
    </ol>

    <details>
      <summary>DeMe 与 Loss Reweighting 的形式等价</summary>
      <div class="expand-body">
        论文在补充材料中证明：DeMe 的解耦-合并框架可以被<strong>形式化地转换为一种 loss 重加权方案</strong>。但传统 loss 重加权是在梯度累加前调权重（梯度方向仍然冲突），而 DeMe 是先让梯度各自走到位（消除冲突），再合并参数（融合知识）——虽然形式等价，但优化路径和最终收敛点完全不同。
      </div>
    </details>

    <details>
      <summary>Channel-wise Projection 的激活分析（Figure 2）</summary>
      <div class="expand-body">
        <img src="img/deme/fig2_channel.png" alt="Figure 2: Channel vs spatial activation differences" style="width:100%; border-radius:8px; margin-bottom:14px;" loading="lazy">
        论文可视化了微调前后的激活差异，比较了通道维度和空间维度：<br><br>
        <strong>通道维度</strong>：激活值变化显著，分布差异明显<br>
        <strong>空间维度</strong>：激活值变化很小，分布差异不明显<br><br>
        这说明时间步特定的知识主要编码在<strong>通道映射</strong>中而非空间映射中——这就是 Channel-wise Projection（C×C 矩阵）比全连接层或空间注意力更合适的原因：它精准地作用在知识差异最大的维度上。
      </div>
    </details>
  </section>

  <hr class="sep">

  <!-- ═══════════════════════ §5 SYNTHESIS ═══════════════════════ -->
  <section id="takeaway-section">
    <div class="section-num">综合</div>
    <h2>设计蓝图：从论文到实践</h2>
    <p class="section-hook">提炼方法论层面的启示</p>

    <ol class="causal">
      <li><strong>"训练即多任务"</strong>——扩散模型的时间步共享参数本质上是多任务学习。一旦建立这个认知，MTL 领域数十年的研究工具（梯度手术、参数隔离、任务聚类）都可以借用。</li>
      <li><strong>"隔离-再融合"优于"调权重"</strong>——loss 重加权只能调"音量"，不能消除方向冲突。DeMe 的路径是先物理隔离冲突，再在参数空间找到全局最优融合点。</li>
      <li><strong>Task Arithmetic 的威力</strong>——参数合并不是简单取平均，而是在高维参数空间中做向量运算。task vector 的加权组合可以找到比任何单个模型都更好的位置。</li>
      <li><strong>微调阶段的成本换推理阶段的免费</strong>——N 倍微调成本，但推理完全零开销。对于部署场景（推理 >> 训练），这是极好的成本结构。</li>
      <li><strong>可能的泛化</strong>——论文指出，这种"任务特定训练 + 参数空间合并"的框架不限于扩散模型，可以推广到一般的多任务学习场景。</li>
    </ol>
  </section>

  <!-- ═══════════════════════ TAKEAWAY ═══════════════════════ -->
  <div class="takeaway">
    <div class="thesis-label">Takeaway</div>
    <p>
      扩散模型共享参数是一种强假设，它带来了训练效率但也带来了梯度冲突。DeMe 的贡献不在于某个具体的 trick，而在于<strong>提出了一个正确的问题框架</strong>：把扩散模型训练视为多任务学习，问题就从"如何调 loss 权重"变成了"如何管理任务间的知识共享与冲突隔离"——后者有更大的解空间，也通向更好的解。
    </p>
  </div>

  <footer>
    原文 by <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Decouple-Then-Merge_Finetune_Diffusion_Models_as_Multi-Task_Learning_CVPR_2025_paper.pdf" target="_blank">Ma et al., CVPR 2025</a>
    · <a href="/">← 首页</a>
  </footer>

</div>

<script>
window.addEventListener('scroll', () => {
  const h = document.documentElement;
  const pct = (h.scrollTop / (h.scrollHeight - h.clientHeight)) * 100;
  document.getElementById('progress').style.width = Math.min(pct, 100) + '%';
}, { passive: true });

const toc = document.getElementById('toc');
if (toc) {
  const links = [...toc.querySelectorAll('a')];
  const targets = links.map(a => document.querySelector(a.getAttribute('href'))).filter(Boolean);
  const update = () => {
    let current = '';
    for (const t of targets) {
      if (t.getBoundingClientRect().top <= 140) current = t.id;
    }
    links.forEach(a => a.classList.toggle('active', a.getAttribute('href') === '#' + current));
  };
  window.addEventListener('scroll', update, { passive: true });
  update();
}
</script>

</body>
</html>
